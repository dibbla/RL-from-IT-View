# RL-from-IT-View
A project repository discussing basic Reinforcement Learning algorithms from a Information Theory View

## Roadmap
- [ ] Set up the maze environment
- [ ] Generate expert trajectories with common baseline algorithms
- [ ] Run Behavior Clone on expert trajectories (no data-drifting)
- [ ] Run DQN on maze environment directly (data-drifting)
- [ ] More training with varying Memeory Equivalent Capacity (MEC)

## Environment setup
We use `minigrid` based on `gymnasium`, which is the *"more modern"* version of OpenAI Gym.